{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a dataset containing a unique gameid and its name\n",
    "Names = pd.read_csv('game_names.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the twitch data. Twitch data contains games that are not contained in prize data and vice versa.\n",
    "# Thus when we merge them, we will only use ones that shows up in both data. \n",
    "twitch = pd.read_csv('twitch.csv')\n",
    "data = pd.merge(Names, twitch, on='GameName', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now twitch data is cleaned. We will clean country_lang dataset\n",
    "\n",
    "language = pd.read_csv('country_lang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While scraping, we scraped something that are relavant, and they have shown up as missing value, so we will drop them.\n",
    "language = language.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language value contains comma and also sometimes it contains multiple language. We will pick the first one and drop the rest. \n",
    "def string(text):\n",
    "    text = str(text)\n",
    "    return text.split(',')[0]\n",
    "\n",
    "language['language'] = language['language'].apply(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have cleaned the country_lang dataset, we can attach a language to the country data contained in broadband data. \n",
    "\n",
    "broad = pd.read_csv('broadband.csv')\n",
    "broad = pd.merge(broad, language, left_on='Entity', right_on = 'country',how='inner')\n",
    "broad.drop('country', axis=1)\n",
    "\n",
    "# Now broadband data has language data attached to it. We want to make sure that language here is consistent with the language\n",
    "# used in the twitch data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have a consistent language, take the symmetric difference of language sets to see what language is lacking. \n",
    "twi_lan = set(twitch['language'].unique())\n",
    "bro_lan = set(broad['language'].unique())\n",
    "print(twi_lan - bro_lan)\n",
    "print(bro_lan - twi_lan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First langauge such as Chinese (Taiwan), Spanish (Mexico), etc must be Chinese and Spanish respectively. \n",
    "twitch['language'].loc[twitch['language']== 'Chinese (Hong Kong SAR)'] = 'Chinese'\n",
    "twitch['language'].loc[twitch['language']== 'Chinese (Taiwan)'] = 'Chinese'\n",
    "twitch['language'].loc[twitch['language']== 'Spanish (Mexico)'] = 'Spanish'\n",
    "twitch['language'].loc[twitch['language']== 'Portuguese (Brazil)'] = 'Portuguese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will still need to fix languages such as ltailans and Italian. \n",
    "# Also broadband do not have language named Czech and Polish. Moreover, Mandarin must be changed to Chinese. \n",
    "broad['language'].loc[broad['language'] == 'Catalan'] = 'Catalans'\n",
    "broad['language'].loc[broad['language'] == 'Italian'] = 'Italians'\n",
    "broad['language'].loc[broad['language'] == 'Hungarian'] = 'Hungarians'\n",
    "broad['language'].loc[broad['language'] == 'Modern Greek'] = 'Greek'\n",
    "broad['language'].loc[broad['language'] == 'Malay'] = 'Malaysian'\n",
    "broad['language'].loc[broad['language'] == 'Mandarin'] = 'Chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitch data contains the language called Polish, but we do not have polish in our sample. \n",
    "# For that reason we will assign German to Polish in Twitch data. \n",
    "twitch['language'].loc[twitch['language']== 'Polish'] = 'German'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the remaining language in bro_lan - twi_lan should be converted to Other category. \n",
    "# Put the set_prize - set_twitch language category to Other category. \n",
    "wi_lan = set(twitch['language'].unique())\n",
    "bro_lan = set(broad['language'].unique())\n",
    "\n",
    "# Create a function that converts rest of them to \"Other\"\n",
    "def change_names(textstr):\n",
    "    if textstr in list(bro_lan - wi_lan):\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return textstr\n",
    "\n",
    "# Run the function on the dataframe  \n",
    "broad['language']=broad['language'].apply(change_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have fixed that, let us check again if we still need any fix. \n",
    "# Note that broadband data do not have Czech in the sample. So we will drop it when merging twitch and broadband data. \n",
    "# Moreover, All languages and American Sign Language will also be dropped when merging. \n",
    "twi_lan = set(twitch['language'].unique())\n",
    "bro_lan = set(broad['language'].unique())\n",
    "print(twi_lan - bro_lan)\n",
    "print(bro_lan - twi_lan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that twitch data and broadband data is cleaned, we will now clean the Prize data. However, doing this is a difficult task. \n",
    "# First of all, prize data contain location information that is just not formatted in a consistent format. \n",
    "# Second of all, the data does not contain the game name. So we will do that as well. \n",
    "# Thirdly, I would like to create a seperate column for year and month using startdata as date. \n",
    "\n",
    "prize = pd.read_csv('prize_money.csv')\n",
    "game_nam = pd.read_csv('game_names.csv')\n",
    "\n",
    "# First let us merge two data using GameID as a key. \n",
    "prize = pd.merge(prize, game_nam, on='GameId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year and month column\n",
    "month_names = {\n",
    "    1: 'january', 2: 'february', 3: 'march', 4: 'april',\n",
    "    5: 'may', 6: 'june', 7: 'july', 8: 'august',\n",
    "    9: 'september', 10: 'october', 11: 'november', 12: 'december'\n",
    "}\n",
    "\n",
    "prize[\"date\"]= pd.to_datetime(prize['StartDate'], format='%m/%d/%y', errors='coerce')\n",
    "# One data contains NA value. \n",
    "prize[prize['date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fix NA value and run the code again. \n",
    "\n",
    "prize.loc[47592, 'StartDate'] = '5/7/20'\n",
    "\n",
    "prize[\"date\"]= pd.to_datetime(prize['StartDate'], format='%m/%d/%y', errors='coerce')\n",
    "prize[prize['date'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the year and month column and drop StartDate and EndDate. \n",
    "prize['year'] = prize['date'].dt.year\n",
    "prize['month'] = prize['date'].dt.month.map(month_names)\n",
    "prize = prize.drop(['StartDate','EndDate'], axis=1)\n",
    "prize.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we would like to clean the location data. To do this, we will make things consistent by converting all into a lowercase.\n",
    "prize[\"Location\"] = prize['Location'].str.lower()\n",
    "\n",
    "# Our strategy is to take the unique value of each location data and convert them into a dataframe. \n",
    "# Then find a corresponding country data using a library. \n",
    "\n",
    "location = pd.DataFrame({'location': list(prize['Location'].str.lower().unique())})\n",
    "location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take the locaiton data and find the corresponding country. \n",
    "# Running this might take a while. \n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_country(location):\n",
    "    geolocator = Nominatim(user_agent=\"location_identifier\")\n",
    "    location_info = geolocator.geocode(location, language='en', timeout=10)\n",
    "    \n",
    "    if location_info:\n",
    "        return location_info.address.split(\",\")[-1].strip()\n",
    "    else:\n",
    "        return \"Not Found\"\n",
    "\n",
    "# We will assign the country and save it to location.csv so that we do not need to run it again. \n",
    "location['country'] = location['location'].apply(get_country)\n",
    "location.to_csv('uni_loc1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "location = pd.read_csv('/Users/yuyaogawa/Documents/Home Work/Research with Dr. Ward/uni_loc1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function has assigned 116 unique country to the location data. However, some of them are not accurate. \n",
    "pd.DataFrame(location['country'].unique()).count()\n",
    "\n",
    "# I attempted to find an efficient way to fix this, but manually fixing it turned out to be the easiest solution. \n",
    "# I have created a csv file that is already fixed and combined them with the prize data, and we will download it here.\n",
    "# The data file is available upon request: yuya19991230@gmail.com\n",
    "\n",
    "prize = pd.read_csv('clean_prize_money.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = pd.DataFrame(prize['GameName'].unique()).sort_values(by=0).reset_index(drop=True)\n",
    "\n",
    "# We will create a column containing the first word of the game name. \n",
    "game[1] = game[0].str.split().str.get(0)\n",
    "\n",
    "# Seems like the games that share the same first word are essentially the equivalent games. \n",
    "\n",
    "# Create a column called name\n",
    "game['name'] = 0\n",
    "game.at[0, 'name'] = 'ARMS'\n",
    "# The following code will give the same name of the game if the first word is the same. \n",
    "for i in range(len(game)-1):\n",
    "    if game.iloc[i][1] == game.iloc[i+1][1]:\n",
    "        game.at[i+1, 'name'] = game.iloc[i]['name']\n",
    "    else:\n",
    "        game.at[i+1, 'name'] = game.iloc[i+1][0]\n",
    "\n",
    "# Result is successful. \n",
    "game = game.drop(1, axis=1)\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have identified equivalent games, we will merge game column and prize column using 0 as a key. \n",
    "# We will merge the game name data with twitch as well.\n",
    "\n",
    "prize = pd.merge(prize, game, left_on='GameName', right_on=0)\n",
    "prize = prize.drop(['GameName', 0], axis = 1)\n",
    "prize = prize.rename(columns={'name': 'GameName'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitch = pd.merge(twitch, game, left_on='GameName', right_on=0)\n",
    "twitch = twitch.drop(['GameName', 0], axis = 1)\n",
    "twitch = twitch.rename(columns={'name': 'GameName'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before merging this dataset with broadband data, we need to aggregate prize data as well. \n",
    "# We will do so by taking the average and std conditional on country, GameName, and year. \n",
    "\n",
    "prize = prize.groupby(['country', 'year', 'GameName', 'language']).agg({\n",
    "    'TotalUSDPrize': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "prize.columns = [f'{col[0]}_{col[1]}' if col[1] != '' else col[0] for col in prize.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prize.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the prize data is fixed. \n",
    "# Now we will merge broadband data and prize data using country and year as a key. \n",
    "# broad contains irrelevant columns so we will drop them.\n",
    "broad = broad.drop(['Entity', 'Code'], axis = 1)\n",
    "broad = broad.rename(columns={'Year':'year'})\n",
    "prize = pd.merge(prize, broad, on = ['country', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will keep the language_y which is consistent with twitch data. \n",
    "prize = prize.drop('language_x', axis=1)\n",
    "prize = prize.rename(columns={'language_y':'language'})\n",
    "prize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we merge twitch data with the rest of them, we would like to merge using year and country as a key. \n",
    "# But the problem is that twitch data is monthly data and broadband is an yearly data. \n",
    "# For above reason, we will have to aggregate twitch data into an yearly data. \n",
    "# To do this, we will take the average of view times, stream times, etc, conditional on games, year, and language. \n",
    "# In aggregated twitch data, We will create a column called average and standard deviation. \n",
    "\n",
    "agg_twitch = twitch.groupby(['year', 'language', 'GameName']).agg({\n",
    "    'watch_time_min': ['mean', 'std'],\n",
    "    'stream_time_min': ['mean', 'std'],\n",
    "    'peak_viewers': ['mean', 'std'],\n",
    "    'peak_channels': ['mean', 'std'],\n",
    "    'streamers': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "agg_twitch.columns = [f'{col[0]}_{col[1]}' if col[1] != '' else col[0] for col in agg_twitch.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(agg_twitch), len(prize), len(broad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have aggregated data for twitch, we can merge prize data and twitch using language, year, and GameName as a key.\n",
    "# Before that, we will drop the country column from prize data. \n",
    "prize = prize.drop('country', axis=1)\n",
    "final_data = pd.merge(prize, agg_twitch, on=['year', 'language','GameName'], how='inner')\n",
    "final_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('final_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
